<!doctype html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="欢迎戳进" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="唐相儒TANG的博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="唐相儒TANG的博客">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="唐相儒TANG的博客">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> 唐相儒TANG的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">唐相儒TANG的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/首页" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/目录" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/标签" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/04/bop资格赛弃坑之路/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/04/bop资格赛弃坑之路/" itemprop="url">
                  bop资格赛弃坑之路
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-04T01:37:09+08:00">
                2017-06-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="bop资格赛弃坑之路"><a href="#bop资格赛弃坑之路" class="headerlink" title="bop资格赛弃坑之路"></a>bop资格赛弃坑之路</h1><p>由于这次资格赛涉及了过多的高级操作，就算会写bot也过不了资格赛，就比较无语，但是还是学到了些东西的</p>
<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>资格赛任务题是基于文档的问答任务（Document-based Question Answering task, DBQA），它是对于给定的一篇文档（Document）和一个从文档中提出的自然语言问题(Question)，参赛队伍需要使用提供的数据集训练模型算法，让模型可以回答问题，回答时仅限于从组成该文档的句子中选出能回答该问题的句子（Answer Selection in Question Answering）。鼓励参赛队伍发挥算法创造力并使用各种资源来训练模型，比如句子匹配模型（Sentence Matching Model），以使模型能准确地回答问题。</p>
<p><a href="https://msc.blob.core.chinacloudapi.cn/mscmedia/BoP2017_DBQA_dev_train_data.rar" target="_blank" rel="external">训练集和开发集</a></p>
<h1 id="基于文档的问答系统DBQA"><a href="#基于文档的问答系统DBQA" class="headerlink" title="基于文档的问答系统DBQA"></a>基于文档的问答系统DBQA</h1><p>给出了训练数据开发数据测试数据，训练数据给出了三元组，问题是同样的问题，七句话来自同一个篇章。第一列是答案标签，第六行是1：是答案，其他不是答案：是0。任务是：给你一个篇章再给一个问题，选出篇章中的一句来保证这是当前问题的答案。根据答案标签来训练问题答案句匹配模型，但是实际测试时只会给当前的篇章和问题，没有答案标签，要排序，排出最相关的一句话</p>
<p>提示：1、数数，重复的字词很多，就有问题答案关系</p>
<p>2、词向量。每个句子都可以转化成词向量，表示当前词的语言。然后看词向量上的距离</p>
<p>3、深度学习工具，做模型上的训练，使问题和正确答案相关性非常强，以实现答案抽取</p>
<p><a href="http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html" target="_blank" rel="external">一个句子匹配模型的神经网络的构造</a></p>
<h1 id="胡老师"><a href="#胡老师" class="headerlink" title="胡老师"></a>胡老师</h1><p>用深度学习做文本领域的自动问答，分析输入问题基于文本的内容来给出答案</p>
<p>最土的做法：端对端的基于神经网络的自动问答模型，需要基于LSTM模型及其变体，比如有需要有web记忆模块的功能；再比如说用gru编码给定的文本信息作为知识，在编码给定信息的时候要用词向量表示文本，然后用gru表示给定的问题</p>
<p>然后用attention机制来表示问题和需要记忆的答案和情景之间的交互来生成答案，所以是一个需要用动态神经网络机制来实现的端对端的联合训练的神经网络系统。</p>
<p>要做的话建议用双向的LSTM模型来同时建立问题和文档的联合表示，然后通过一个分类器来预测答案。</p>
<h1 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h1><p>谷歌就开源了其用来制作AlphaGo的深度学习系统Tensorflow<br><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bf8fe82dca.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install python-pip python-dev</div><div class="line"></div><div class="line">$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl</div><div class="line"></div><div class="line">($ pip install --upgrade pip)</div></pre></td></tr></table></figure>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bfc1f5cf0c.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bfbfba1d0c.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bfcbf992d4.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bfde052a03.jpg?imageMogr2/format/jpg/quality/90" alt=""></p>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bfd275fb93.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201606/575bfd31af585.png?imageMogr2/format/jpg/quality/90" alt=""></p>
<p>！！！ <a href="http://www.cnblogs.com/hellocwh/p/5623179.html" target="_blank" rel="external">看看</a></p>
<h1 id="attention机制"><a href="#attention机制" class="headerlink" title="attention机制"></a>attention机制</h1><p>真正火起来应该算由于是google mind团队的这篇论文《Recurrent Models of Visual Attention，他们在RNN模型上使用了attention机制来进行图像分类。<br>随后，Bahdanau等人在论文《Neural Machine Translation by Jointly Learning to Align and Translate》 [1]中，使用类似attention的机制在机器翻译任务上将翻译和对齐同时进行，他们的工作算是是第一个提出attention机制应用到NLP领域中。接着类似的基于attention机制的RNN模型扩展开始应用到各种NLP任务中。最近，如何在CNN中使用attention机制也成为了大家的研究热点</p>
<p><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111501343-1669960587.png" alt=""></p>
<h2 id="《Recurrent-Models-of-Visual-Attention》"><a href="#《Recurrent-Models-of-Visual-Attention》" class="headerlink" title="《Recurrent Models of Visual Attention》"></a>《Recurrent Models of Visual Attention》</h2><p>他们研究的动机是受到人类注意力机制的启发。人们在进行观察图像的时候，其实并不是一次就把整幅图像的每个位置像素都看过，大多是根据需求将注意力集中到图像的特定部分.</p>
<p><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111502375-2099469126.png" alt=""></p>
<p>该模型是在传统的RNN上加入了attention机制（即红圈圈出来的部分），通过attention去学习一幅图像要处理的部分，每次当前状态，都会根据前一个状态学习得到的要关注的位置l和当前输入的图像，去处理注意力部分像素，而不是图像的全部像素。这样的好处就是更少的像素需要处理，减少了任务的复杂度。可以看到图像中应用attention和人类的注意力机制是很类似的，接下来我们看看在NLP中使用的attention。</p>
<h2 id="Attention-based-RNN-in-NLP"><a href="#Attention-based-RNN-in-NLP" class="headerlink" title="Attention-based RNN in NLP"></a>Attention-based RNN in NLP</h2><p>他们把attention机制用到了神经网络机器翻译（NMT）上，NMT其实就是一个典型的sequence to sequence模型，也就是一个encoder to decoder模型，传统的NMT使用两个RNN，一个RNN对源语言进行编码，将源语言编码到一个固定维度的中间向量，然后在使用一个RNN进行解码翻译到目标语言，传统的模型如下图：<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111502937-1550553767.png" alt=""></p>
<p>这篇论文提出了基于attention机制的NMT，模型大致如下图：<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111503843-584496480.png" alt=""><br>图中我并没有把解码器中的所有连线画玩，只画了前两个词，后面的词其实都一样。可以看到基于attention的NMT在传统的基础上，它把源语言端的每个词学到的表达（传统的只有最后一个词后学到的表达）和当前要预测翻译的词联系了起来，这样的联系就是通过他们设计的attention进行的，在模型训练好后，根据attention矩阵，我们就可以得到源语言和目标语言的对齐矩阵了。具体论文的attention设计部分如下：<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111504671-910168246.png" alt=""><br>可以看到他们是使用一个感知机公式来将目标语言和源语言的每个词联系了起来，然后通过soft函数将其归一化得到一个概率分布，就是attention矩阵。<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111505140-1405381433.png" alt=""><br>从结果来看相比传统的NMT（RNNsearch是attention NMT，RNNenc是传统NMT）效果提升了不少，最大的特点还在于它可以可视化对齐，并且在长句的处理上更有优势。</p>
<h2 id="Effective-Approaches-to-Attention-based-Neural-Machine-Translation"><a href="#Effective-Approaches-to-Attention-based-Neural-Machine-Translation" class="headerlink" title="Effective Approaches to Attention-based Neural Machine Translation"></a>Effective Approaches to Attention-based Neural Machine Translation</h2><p>他们的工作告诉了大家attention在RNN中可以如何进行扩展，这篇论文对后续各种基于attention的模型在NLP应用起到了很大的促进作用。在论文中他们提出了两种attention机制，一种是全局（global）机制，一种是局部（local）机制。</p>
<p>作者的实验结果是局部的比全局的attention效果好。</p>
<p>这篇论文最大的贡献我觉得是首先告诉了我们可以如何扩展attention的计算方式，还有就是局部的attention方法。</p>
<h2 id="Attention-based-CNN-in-NLP"><a href="#Attention-based-CNN-in-NLP" class="headerlink" title="Attention-based CNN in NLP"></a>Attention-based CNN in NLP</h2><p>随后基于Attention的RNN模型开始在NLP中广泛应用，不仅仅是序列到序列模型，各种分类问题都可以使用这样的模型。那么在深度学习中与RNN同样流行的卷积神经网络CNN是否也可以使用attention机制呢？《ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs》这篇论文就提出了3中在CNN中使用attention的方法，是attention在CNN中较早的探索性工作。</p>
<p>传统的CNN在构建句对模型时如上图，通过每个单通道处理一个句子，然后学习句子表达，最后一起输入到分类器中。这样的模型在输入分类器前句对间是没有相互联系的，作者们就想通过设计attention机制将不同cnn通道的句对联系起来。</p>
<p>第一种方法ABCNN0-1是在卷积前进行attention，通过attention矩阵计算出相应句对的attention feature map，然后连同原来的feature map一起输入到卷积层。具体的计算方法如下。<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111509265-808480223.png" alt=""><br>第二种方法ABCNN-2是在池化时进行attention，通过attention对卷积后的表达重新加权，然后再进行池化，原理如下图。<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111510078-1490972209.png" alt=""><br>第三种就是把前两种方法一起用到CNN中，如下图<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111510750-1137702886.png" alt=""><br>这篇论文提供了我们在CNN中使用attention的思路。现在也有不少使用基于attention的CNN工作，并取得了不错的效果。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Attention在NLP中其实我觉得可以看成是一种自动加权，它可以把两个你想要联系起来的不同模块，通过加权的形式进行联系。目前主流的计算公式有以下几种：</p>
<p>通过设计一个函数将目标模块mt和源模块ms联系起来，然后通过一个soft函数将其归一化得到概率分布。<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111511390-885545526.png" alt=""><br>目前Attention在NLP中已经有广泛的应用。它有一个很大的优点就是可以可视化attention矩阵来告诉大家神经网络在进行任务时关注了哪些部分。<br><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111512000-2137971007.png" alt=""><br>不过在NLP中的attention机制和人类的attention机制还是有所区别，它基本还是需要计算所有要处理的对象，并额外用一个矩阵去存储其权重，其实增加了开销。而不是像人类一样可以忽略不想关注的部分，只去处理关注的部分。</p>
<p>!!!!<img src="一个具体处理文本分类问题" alt=""></p>
<h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1><p>Numpy是Python的一个科学计算的库，提供了矩阵运算的功能，其一般与Scipy、matplotlib一起使用。其实，list已经提供了类似于矩阵的表示形式，不过numpy为我们提供了更多的函数。</p>
<p>在 numpy 包中我们用数组来表示向量，矩阵和高阶数据结构。他们就由数组构成，一维就用一个数组表示，二维就是数组中包含数组表示。</p>
<p><a href="http://www.jb51.net/article/103080.htm" target="_blank" rel="external">入门</a></p>
<p><a href="http://www.jb51.net/article/49397.htm" target="_blank" rel="external">计算</a></p>
<p>矩阵的余弦看相似度</p>
<h1 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h1><p>singular value decomposition是线性代数中一种重要的矩阵分解，在信号处理、统计学等领域有重要应用。 奇异值分解在某些方面与对称矩阵或厄米矩陣基于特征向量的对角化类似。<br><a href="http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm" target="_blank" rel="external">svd</a></p>
<h1 id="gru模型"><a href="#gru模型" class="headerlink" title="gru模型"></a>gru模型</h1><p>GRU模型与LSTM模型设计上十分的相似，LSTM包含三个门函数（input gate、forget gate和output gate)，而GRU模型是LSTM模型的简化版，仅仅包含两个门函数（reset gate和update gate）。reset gate决定先前的信息如何结合当前的输入，update gate决定保留多少先前的信息。如果将reset全部设置为1，并且update gate设置为0，则模型退化为RNN模型。<br><img src="http://upload-images.jianshu.io/upload_images/5005591-7b994fb1cf09a213.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br><img src="http://upload-images.jianshu.io/upload_images/5005591-706659766b06ceed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>从上面GRU模型和LSTM模型的定义可总结出区别如下</p>
<p>1：GRU包含2个门函数、LSTM包含三个门函数。</p>
<p>2：GRU模型没有output gate，因此它不需要计算输出。</p>
<p>3：LSTM中input gate和forget gate的作用分别为控制输入的信息和控制先前的信息。而GRU中由update gate同时控制输入和先前的信息，即公式中变量z。reset gate直接应用于先前的隐藏状态的控制，即公式中变量f。这样LSTM中reset的作用由GRU中reset和update gate共同完成。</p>
<p>4：输出不再需要加入一个非线性函数。</p>
<p>LSTM模型和GRU模型在应用中的选择</p>
<p>1：从上面的区别可以看出，GRU模型的参数相对更少，因此训练的速度会稍快，从实验中也可以得出该结论。</p>
<p>2：当你的训练数据足够多的时候，LSTM模型会表现的更好。</p>
<p>实验步骤</p>
<p>1：本次实验采用insuranceQA数据，你可以在这里获得。实验之前首先对问题和答案按字切词，然后采用word2vec对问题和答案进行预训练（这里采用按字切词的方式避免的切词的麻烦，并且同样能获得较高的准确率）。</p>
<p>2：由于本次实验采用固定长度的GRU，因此需要对问题和答案进行截断（过长）或补充（过短）。</p>
<p>3：实验建模Input。本次实验采用问答对的形式进行建模（q，a+，a-），q代表问题，a+代表正向答案，a-代表负向答案。insuranceQA里的训练数据已经包含了问题和正向答案，因此需要对负向答案进行选择，实验时我们采用随机的方式对负向答案进行选择，组合成（q，a+，a-）的形式。</p>
<p>4：将问题和答案进行Embedding（batch_size, sequence_len, embedding_size）表示。</p>
<p>5：对问题和答案采用相同的GRU模型计算特征（sequence_len, batch_size, rnn_size）。</p>
<p>6：对时序的GRU特征进行选择，这里采用max-pooling。</p>
<p>7：采用问题和答案最终计算的特征，计算目标函数（cosine_similary）。<br><img src="http://upload-images.jianshu.io/upload_images/5005591-46fc9baca40fadc8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br>参数设置</p>
<p>1:、这里优化函数采用论文中使用的SGD（采用adam优化函数时效果会差大概2个点）。</p>
<p>2、学习速率为0.1。</p>
<p>3:、训练100轮，大概需要6个小时的时间。</p>
<p>4、margin这里采用0.15，其它参数也试过0.05、0.1效果一般。</p>
<p>5、这里训练没有采用dropout和l2约束，之前试过dropout和l2对实验效果没有提升，这里就没有采用了。</p>
<p>6、batch_size这里采用问题30字、答案100字。</p>
<p>7、rnn_size为150（继续调大没有明显的效果提升，而且导致训练速度减慢）</p>
<p>8、目标函数采用cosine_similary。</p>
<p>实验效果对比</p>
<p>QA_CNN：0.62左右</p>
<p>QA_LSTM：0.66左右</p>
<p>QA_BILSTM：0.68左右</p>
<p>QA_GRU :0.6378左右</p>
<p>QA_BIGRU ：0.669左右</p>
<p>注：这里分别实验了单向的GRU算法、双向的GUR算法、单向的LSTM和双向的LSTM算法。单向GRU/LSTM的算法只能捕获当前词之前词的特征，而双向的GRU/LSTM算法则能够同时捕获前后词的特征，实验证明双向的GRU/LSTM比单向的GRU/LSTM算法效果更佳。LSTM算法性能稍优于GRU算法，但是GRU算法训练速度要比LSTM算法快。实际使用可以根据自己的要求做出权衡。</p>
<p>!!!!!！！！ <a href="https://zhuanlan.zhihu.com/p/22577648" target="_blank" rel="external">gru模型算法和qa</a></p>
<h1 id="LSTM模型"><a href="#LSTM模型" class="headerlink" title="LSTM模型"></a>LSTM模型</h1><h1 id="nlpir汉语分词系统"><a href="#nlpir汉语分词系统" class="headerlink" title="nlpir汉语分词系统"></a>nlpir汉语分词系统</h1><p><a href="http://ictclas.nlpir.org/" target="_blank" rel="external">网址</a><br>可以线上演示</p>
<h1 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h1><p>word2vec是Google于2013年开源推出的一个用于获取词向量的工具包</p>
<p>从官方的介绍可以看出word2vec是一个将词表示为一个向量的工具，通过该向量表示，可以用来进行更深入的自然语言处理，比如机器翻译等。</p>
<h2 id="N-gram模型"><a href="#N-gram模型" class="headerlink" title="N-gram模型"></a>N-gram模型</h2><p>通过上面的语言模型计算的例子，大家可以发现，如果一个句子比较长，那么它的计算量会很大；</p>
<p>牛逼的科学家们想出了一个N-gram模型来简化计算，在计算某一项的概率时Context不是考虑前面所有的词，而是前N-1个词；</p>
<p>当然牛逼的科学家们还在此模型上继续优化，比如N-pos模型从语法的角度出发，先对词进行词性标注分类，在此基础上来计算模型的概率；后面还有一些针对性的语言模型改进，这里就不一一介绍。</p>
<p>通过上面简短的语言模型介绍，我们可以看出核心的计算在于P(wi|Contenti)，对于其的计算主要有两种思路：一种是基于统计的思路，另外一种是通过函数拟合的思路；前者比较容易理解但是实际运用的时候有一些问题（比如如果组合在语料里没出现导致对应的条件概率变为0等），而函数拟合的思路就是通过语料的输入训练出一个函数P(wi|Contexti) = f(wi,Contexti;θ)，这样对于测试数据就直接套用函数计算概率即可，这也是机器学习中惯用的思路之一。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">// One-hot Representation 向量的维度是词表的大小，比如有10w个词，该向量的维度就是10w</div><div class="line">v(&apos;足球&apos;) = [0 1 0 0 0 0 0 ......]</div><div class="line">v(&apos;篮球&apos;) = [0 0 0 0 0 1 0 ......]</div><div class="line"></div><div class="line">// Distributed Representation 向量的维度是某个具体的值如50</div><div class="line">v(&apos;足球&apos;) = [0.26 0.49 -0.54 -0.08 0.16 0.76 0.33 ......]</div><div class="line">v(&apos;篮球&apos;) = [0.31 0.54 -0.48 -0.01 0.28 0.94 0.38 ......]</div></pre></td></tr></table></figure>
<h2 id="词向量表示"><a href="#词向量表示" class="headerlink" title="词向量表示"></a>词向量表示</h2><p>自然语言理解的问题要转化为机器学习的问题，第一步肯定是要找一种方法把这些符号数学化。</p>
<p>最直观的就是把每个词表示为一个很长的向量。这个向量的维度是词表的大小，其中绝大多数元素为0，只有一个维度的值为1，这个维度就代表了当前的词。这种表示方式被称为One-hot Representation。这种方式的优点在于简洁，但是却无法描述词与词之间的关系。</p>
<p>另外一种表示方法是通过一个低维的向量（通常为50维、100维或200维），其基于“具有相似上下文的词，应该具有相似的语义”的假说，这种表示方式被称为Distributed Representation。它是一个稠密、低维的实数向量，它的每一维表示词语的一个潜在特征，该特征捕获了有用的句法和语义特征。其特点是将词语的不同句法和语义特征分布到它的每一个维度上去表示。这种方式的好处是可以通过空间距离或者余弦夹角来描述词与词之间的相似性。</p>
<h2 id="神经网络概率语言模型"><a href="#神经网络概率语言模型" class="headerlink" title="神经网络概率语言模型"></a>神经网络概率语言模型</h2><p>神经网络概率语言模型（NNLM）把词向量作为输入（初始的词向量是随机值），训练语言模型的同时也在训练词向量，最终可以同时得到语言模型和词向量。</p>
<p>Bengio等牛逼的科学家们用了一个三层的神经网络来构建语言模型，同样也是N-gram 模型。 网络的第一层是输入层，是是上下文的N-1个向量组成的(n-1)m维向量；第二层是隐藏层，使用tanh作为激活函数；第三层是输出层，每个节点表示一个词的未归一化概率，最后使用softmax激活函数将输出值归一化。</p>
<p>得到这个模型，然后就可以利用梯度下降法把模型优化出来，最终得到语言模型和词向量表示。<br><img src="http://upload-images.jianshu.io/upload_images/3709321-7651f3824d22f7e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="word2vec的核心模型"><a href="#word2vec的核心模型" class="headerlink" title="word2vec的核心模型"></a>word2vec的核心模型</h2><p>word2vec在NNLM和其他语言模型的基础进行了优化，有CBOW模型和Skip-Gram模型，还有Hierarchical Softmax和Negative Sampling两个降低复杂度的近似方法，两两组合出四种实现。<br>无论是哪种模型，其基本网络结构都是在下图的基础上，省略掉了隐藏层；<br><img src="http://upload-images.jianshu.io/upload_images/3709321-8574a3520e6dc5e3.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="分词处理"><a href="#分词处理" class="headerlink" title="分词处理"></a>分词处理</h2><p>由于word2vec处理的数据是单词分隔的语句，对于中文来说，需要先进行分词处理。这里采用的是中国自然语言处理开源组织开源的<a href="https://github.com/NLPchina/ansj_seg" target="_blank" rel="external">ansj_seg</a>分词器`</p>
<p>分词处理之后的文件内容如下所示：<br><img src="http://upload-images.jianshu.io/upload_images/3709321-cec4035b4e0a496f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="下载实践"><a href="#下载实践" class="headerlink" title="下载实践"></a>下载实践</h2><p>这里我没有从官网下载而是从github上的<a href="https://github.com/svn2github/word2vec" target="_blank" rel="external">svn2github/word2vec</a>项目下载源码，下载之后执行make命令编译，这个过程很快就可以结束。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">./word2vec -train ../corpus_out.txt -output vectors.bin -cbow 0 -size 200 -window 5 -negative 0 -hs 1 -sample 1e-3 -threads 12 -binary 1</div><div class="line"></div><div class="line">// 参数解释</div><div class="line">-train 训练数据 </div><div class="line">-output 结果输入文件，即每个词的向量 </div><div class="line">-cbow 是否使用cbow模型，0表示使用skip-gram模型，1表示使用cbow模型，默认情况下是skip-gram模型，cbow模型快一些，skip-gram模型效果好一些 </div><div class="line">-size 表示输出的词向量维数 </div><div class="line">-window 为训练的窗口大小，5表示每个词考虑前5个词与后5个词（实际代码中还有一个随机选窗口的过程，窗口大小&lt;=5) </div><div class="line">-negative 表示是否使用负例采样方法0表示不使用，其它的值目前还不是很清楚 </div><div class="line">-hs 是否使用Hierarchical Softmax方法，0表示不使用，1表示使用 </div><div class="line">-sample 表示采样的阈值，如果一个词在训练样本中出现的频率越大，那么就越会被采样</div><div class="line">-binary 表示输出的结果文件是否采用二进制存储，0表示不使用（即普通的文本存储，可以打开查看），1表示使用，即vectors.bin的存储类型</div></pre></td></tr></table></figure>
<p>处理结束之后，使用distance命令可以测试处理结果，以下是分别测试【足球】和【改革】的效果：<br><img src="http://upload-images.jianshu.io/upload_images/3709321-e2c98fce5c5b88e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><img src="http://upload-images.jianshu.io/upload_images/3709321-ad577373d29f4ca6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<ul>
<li><p>word2vec的模型是基于神经网络来训练词向量的工具；</p>
</li>
<li><p>word2vec通过一系列的模型和框架对原有的NNLM进行优化，简化了计算但准确度还是保持得很好；</p>
</li>
<li><p>word2vec的主要的应用还是自然语言的处理，通过训练出来的词向量，可以进行聚类等处理，或者作为其他深入学习的输入。另外，word2vec还适用于一些时序数据的挖掘，比如用户商品的浏览分析、用户APP的下载等，通过这些数据的分析，可以得到商品或者APP的向量表示，从而用于个性化搜索和推荐。</p>
</li>
</ul>
<p><a href="http://blog.csdn.net/mytestmy/article/details/26961315" target="_blank" rel="external">深度学习word2vec笔记之基础篇</a></p>
<p>[word2vec词向量训练及中文文本相似度计算] (<a href="http://blog.csdn.net/eastmount/article/details/50637476" target="_blank" rel="external">http://blog.csdn.net/eastmount/article/details/50637476</a>)</p>
<p>所以突然发现是可以做到的，然而没时间了，我要下周就期末考试了，只能很惨的弃坑，不过这个坑要是小学期有时间一定填上</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/28/toefl-conversation-problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/28/toefl-conversation-problem/" itemprop="url">
                  toefl conversation problem
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-28T17:46:45+08:00">
                2017-05-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一、跑题-插入内容"><a href="#一、跑题-插入内容" class="headerlink" title="一、跑题/插入内容"></a>一、跑题/插入内容</h1><p>eaasy读作at see<br><img src="" alt=""><br>offer help=volunteer绝不会是相同的词，否则鄙视干扰项</p>
<p>ok,well,ohhh,see,right,now,then,alright表示停顿，上一个语意群已经结束</p>
<h2 id="1、首段若是跑题，跑题内容鄙必是干扰项"><a href="#1、首段若是跑题，跑题内容鄙必是干扰项" class="headerlink" title="1、首段若是跑题，跑题内容鄙必是干扰项"></a>1、首段若是跑题，跑题内容鄙必是干扰项</h2><p>let me know if you have any questions.在此之前出现的所有内容和今天主旨没有任何关联</p>
<p>so what i can do for you ,so what ca i do for you也是一样</p>
<h2 id="2、首段若是跑题，可以设置为第二题问跑题目的"><a href="#2、首段若是跑题，可以设置为第二题问跑题目的" class="headerlink" title="2、首段若是跑题，可以设置为第二题问跑题目的"></a>2、首段若是跑题，可以设置为第二题问跑题目的</h2><h2 id="3、若是跑题，跑题信息可设置为重听题，问跑题信息和跑题原因"><a href="#3、若是跑题，跑题信息可设置为重听题，问跑题信息和跑题原因" class="headerlink" title="3、若是跑题，跑题信息可设置为重听题，问跑题信息和跑题原因"></a>3、若是跑题，跑题信息可设置为重听题，问跑题信息和跑题原因</h2><p>本来是在聊a，然后学生突然说道b，b说完又回到a，说今天还是说a</p>
<p>跑题提示词，本来是在说专业内容，first i have to ask,how many page do we left</p>
<h1 id="二、主旨题中设置为被否定的信息"><a href="#二、主旨题中设置为被否定的信息" class="headerlink" title="二、主旨题中设置为被否定的信息"></a>二、主旨题中设置为被否定的信息</h1><p>吃火锅不吃、吃烧烤不吃、吃pizza不吃</p>
<p>get the word out=帮助宣传</p>
<h1 id="三、混淆目的主旨和内容主旨"><a href="#三、混淆目的主旨和内容主旨" class="headerlink" title="三、混淆目的主旨和内容主旨"></a>三、混淆目的主旨和内容主旨</h1><p>学生最初来是因为作业不会做———目的主旨，内容主旨———没上课的原因是去照顾朋友</p>
<p>目的主旨———why does see the professor</p>
<p>内容主旨——mainly about\内容主旨——main idea<br><img src="" alt=""><br>drop off my graduation form交</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/20/人民的名义/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/20/人民的名义/" itemprop="url">
                  人民的名义
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-20T13:26:57+08:00">
                2017-05-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>谈谈人名的名义<br>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/20/人民的名义/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/18/编程之美lecture/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/18/编程之美lecture/" itemprop="url">
                  编程之美lecture
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-18T02:07:55+08:00">
                2017-05-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="自动问答系统简介（段楠）"><a href="#自动问答系统简介（段楠）" class="headerlink" title="自动问答系统简介（段楠）"></a>自动问答系统简介（段楠）</h1><p>介绍典型的自动问答系统，包括基于知识库的自动问答（KB-QA）、基于文本的问答（Text-QA）和基于FAQ的问答（Community-QA）等。此外，还会对本次大赛问答任务中涉及到的技术做简要说明。</p>
<p>基于自己学校的网站打造机器人，问题回复和信息抽取，做人机交互。包含很多功能和模块。</p>
<p>任务，方法，涉及到的问答方法作介绍并基于真实实例</p>
<p>系统基于给定的数据库，回答人类提出的问题。</p>
<p>问题类型： 答案是实体，答案是定义，答案是yes/no，答案是意见，比较类问题<br><img src="http://i4.buimg.com/588926/fe458ae723a1af52.png" alt=""></p>
<p>早期qa system是专业特定领域的，后来计算能力的飞跃，允许问答系统到开发领域</p>
<p>三大类：</p>
<h2 id="基于知识的问答系统KBQA"><a href="#基于知识的问答系统KBQA" class="headerlink" title="基于知识的问答系统KBQA"></a>基于知识的问答系统KBQA</h2><p>系统的数据库是结构化的，但是知识库是一些实体之间的关系，实体之间的关系是以抽象的标签的形式存在的 </p>
<p>关键是两点：一是能不能把问题中实际到的实体检测出，另一是问题中提到的实体的关系检测出来</p>
<p>应用：微软的必应bing，可以直接直接结构化的查寻，优点：直接拿到答案，节省用户去结果网页中进行信息再定位</p>
<p>从学校主页上挖掘 主语+谓词+宾语（结构化的三元组），可以回答这样的问题：清华大学校长是谁，先做实体的识别，知识库中知识是以实体和关系来存储。实体识别：清华大学，上下文究竟提到的是关于实体的哪个关系的识别：校长关系，答案检索：&lt;清华大学，校长，邱勇&gt;<br><img src="http://i2.muimg.com/588926/892fd55457e729d8.png" alt=""></p>
<p>那么可是如何做基于给定问题的实体识别和关系识别：</p>
<p>从基本的方法开始，从一些百科类网站来获取实体名称，用上述的知识对输入的问题来标注，来标注问题中究竟提到了哪些关系。其他问题：同一实体有很多不同说法名称，一些细致的地方就要做一些扩展<br><img src="http://i4.buimg.com/588926/2326faebb3da15f4.png" alt=""><br>关系识别：</p>
<p>一类是可以创造基于问题模板的关系识别方法（谁是什么什么创始人—&gt;创始人。人工撰写拓展问题模板或者搜索日志中抽取。要问题模板很全才能完全覆盖）。</p>
<p><img src="http://i4.buimg.com/588926/2326faebb3da15f4.png" alt=""></p>
<p>一类是创造基于关系关键字的方法，创办人–从其他地方抓取关键字都表示了创办人的意思。提示：如果有很多满足当前关系的实体对，可以去海量去文本中挖掘句子，这个句子的条件是同时包含了满足这个关系的某一个实体对。若两个实体出现在一个句子中，这两个实体间又在知识库中存在某关系，那这个句子的其他部分就在对知识库里的这个关系做陈述。通过类似方式来抓取一些知识库中关键多对应的不同的关键字来用于检测问的问题是提到知识库中的哪个关系</p>
<p><img src="http://i4.buimg.com/588926/2eb9d1c89b34c2de.png" alt=""></p>
<h2 id="基于文档的问答系统DBQA"><a href="#基于文档的问答系统DBQA" class="headerlink" title="基于文档的问答系统DBQA"></a>基于文档的问答系统DBQA</h2><p>很多知识是无法经过人类整理编辑录入知识库的，哪怕是google的freebase也是不全面的。需要利用其他一些非结构化的知识，可以基于文档中的句子来进行搜索</p>
<p>应用：问题对应的搜索返回网页中包含的句子和段落很好的回答问的问题，直接就返回了结果</p>
<p><img src="http://i2.muimg.com/588926/892fd55457e729d8.png" alt=""></p>
<p>预选赛中的一个任务：给出了训练数据开发数据测试数据，训练数据给出了三元组，问题是同样的问题，七句话来自同一个篇章。第一列是答案标签，第六行是1：是答案，其他不是答案：是0。任务是：给你一个篇章再给一个问题，选出篇章中的一句来保证这是当前问题的答案。根据答案标签来训练问题答案句匹配模型，但是实际测试时只会给当前的篇章和问题，没有答案标签，要排序，排出最相关的一句话。</p>
<p><img src="http://i2.muimg.com/588926/23b2556b33628d27.png" alt=""></p>
<p>再比如校园机动车公告网页，第四句话是非常相关的，作为答案输出。对文档内容做处理。<br><img src="http://i2.muimg.com/588926/6311113a729b4f74.png" alt=""></p>
<p>提示：1、数数，重复的字词很多，就有问题答案关系 </p>
<p>2、词向量。每个句子都可以转化成词向量，表示当前词的语言。然后看词向量上的距离<br><img src="http://i1.piimg.com/588926/f26e268784c0ee9c.png" alt=""></p>
<p>3、深度学习工具，做模型上的训练，使问题和正确答案相关性非常强，以实现答案抽取</p>
<h2 id="基于社交型（问题答案对）问答形态FAQ-search"><a href="#基于社交型（问题答案对）问答形态FAQ-search" class="headerlink" title="基于社交型（问题答案对）问答形态FAQ search"></a>基于社交型（问题答案对）问答形态FAQ search</h2><p>像百度知道，奖励机制，点赞来提取出高质量的问题和答案对，用历史答案来回复现在的高相似度的问题。</p>
<p>应用：微软小冰，进入公众号后，索引整理该公众号的历史文章，用户会问文章中含有的问题（一般是多引擎协同工作），直接用历史文章中的答案对来回答</p>
<p><img src="http://i4.buimg.com/588926/2326faebb3da15f4.png" alt=""></p>
<p>核心的目的是计算一个输入问题和历史问题的相似度，这就需要一个问题和问题的匹配模型。那么采用如何的训练数据来得到这样一个匹配模型。像百度知道这样来抽取训练数据，页面中会有一堆其他类似问题，即重新定向到历史问题。有这样的问题和相似问题的数据之后就可以训练一个模型，给一个分数来表明两个问题的相似度。</p>
<p><img src="http://i2.muimg.com/588926/520ece09f47ebcb3.png" alt=""></p>
<p>计算相似度是一个语义理解的问题，这是nlp中的最核心问题。概念：有一些方式根据相似数据做模型，如一个词缀对齐。</p>
<p><img src="http://i4.buimg.com/588926/6a2297d0b5d6de26.png" alt=""><br>第二类是同义词和近似词表，另外海量的翻译数据，对翻译数据进行对其之后，一个现象：如果源语言端的两个词或者短语对应的反义词是相同的，则这两个源语言是近似的。同义词的信息抽取</p>
<p>第三类是有了相似问题的海量数据之后，可以用深度学习或者是神经网络模型来做一个模型。概要性解释：把每一个问题转化成一个n维或者是1000维向量，每一个维度都是实值，人觉得是一千个数字，但是机器觉得1000维数字来对问题来编码来保证语意相同的两个句子在向量空间距离上是非常近的。给工具包，看说明</p>
<p><img src="http://i2.muimg.com/588926/d26e73af446318fe.png" alt=""></p>
<p>一些工具包<br>中文分词<br>词向量<br>句子向量<br>语言理解</p>
<p>最后的是去年的评测比赛提供的两个的基准的问答系统的实例。虽然系统非常简单，但可以以此为基础进行扩展</p>
<p><img src="http://i2.muimg.com/588926/3af9354eff4797bd.png" alt=""></p>
<p><img src="http://i2.muimg.com/588926/54ac0b0933462fc6.png" alt=""></p>
<h1 id="如何建立面向任务的自然语言理解模型"><a href="#如何建立面向任务的自然语言理解模型" class="headerlink" title="如何建立面向任务的自然语言理解模型"></a>如何建立面向任务的自然语言理解模型</h1><p>人工智能助理（AI Bot）的一个重要部分是自然语言理解模型。本课程将介绍面向任务的自然语言理解模型，以及如何利用微软认知服务的自然语言理解智能服务（LUIS）快速开发应用合适的模型</p>
<h2 id="什么是面向任务的自然语言理解模型"><a href="#什么是面向任务的自然语言理解模型" class="headerlink" title="什么是面向任务的自然语言理解模型"></a>什么是面向任务的自然语言理解模型</h2><p>三大特点：通过自然语言交互、完成特定的任务、具备一定知识和推理的能力</p>
<p><img src="http://i4.buimg.com/588926/23f46d18a9cee01e.png" alt=""></p>
<h3 id="举例："><a href="#举例：" class="headerlink" title="举例："></a>举例：</h3><p>通过自然语言交互：首先制定会议对应一个功能，team包含一组人，时间地点。慢慢拆解每个句子部分</p>
<p>转入到meeting的功能：四个会议的要素</p>
<p>myteam：office graph</p>
<p>相对时间： 根据测算</p>
<p>地点：</p>
<h2 id="对于面向任务的自然语言bot，他们的模型是两大步"><a href="#对于面向任务的自然语言bot，他们的模型是两大步" class="headerlink" title="对于面向任务的自然语言bot，他们的模型是两大步"></a>对于面向任务的自然语言bot，他们的模型是两大步</h2><p><img src="http://i2.muimg.com/588926/5381215b9d5ed398.png" alt=""></p>
<p>第一步：叫做intent，就是理解用户需要我们做什么。倒过来想，能帮用户做什么。</p>
<p>第二步叫entity，在那句话中给了我们哪些参数。或者说需要哪些参数</p>
<p><img src="http://i1.piimg.com/588926/9d73c4910f23342d.png" alt=""></p>
<h3 id="两部分解决方法"><a href="#两部分解决方法" class="headerlink" title="两部分解决方法"></a>两部分解决方法</h3><p>基于规则：像正则表达式，去纂写规则。当手头上并没有用户数据（冷启动）。成长困难，用户负责性变多，管理这些规则是很难的，尤其是协作、管理数据、标定数据。</p>
<p>基于数据：应用机器学习算法，用数据来学习对应的模型，更可持续</p>
<h2 id="机器学习算法用于自然理解模型中可用于两部分"><a href="#机器学习算法用于自然理解模型中可用于两部分" class="headerlink" title="机器学习算法用于自然理解模型中可用于两部分"></a>机器学习算法用于自然理解模型中可用于两部分</h2><p><img src="http://i1.piimg.com/588926/b30f5a2defe15958.png" alt=""></p>
<p>intent：文本分类问题。线性模型、逻辑回归、cnn、lstm</p>
<p>entity：从一句话中找到相应段落。然后给它一个语义标签。可以变成一个序列标注问题。条件随机场，dl中crf的算法</p>
<p>但是我们今天讲的是基于数据的解决方案</p>
<h2 id="LUIS"><a href="#LUIS" class="headerlink" title="LUIS"></a>LUIS</h2><p><img src="http://i4.buimg.com/588926/be6a353f478f8525.png" alt=""></p>
<p>介绍下：这是个平台化的机器学习解决方案，简答易上手<br><img src="http://i4.buimg.com/588926/ca1020d6421df20e.png" alt=""></p>
<p>通过内建减少feature上花费的时间，高阶语言的表示。两个常用特征：entity的列表和正则表达式</p>
<p>基本工具：解析时间、标注器、很多领域的工具</p>
<p>suggestion：通过主动学习</p>
<h2 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h2><p><img src="http://i4.buimg.com/588926/656cda211c14f672.png" alt=""></p>
<p>先登录，跳转到my apps，点new apps。dashboard，放了常见信息。</p>
<p>点开intent，增加新的:查考分</p>
<p><img src="ttp://i4.buimg.com/588926/bd4248823a334cd6.png" alt=""></p>
<p>输入一些utterance：如计算机系的录取分数线是多少，然后save。所以同时想到要在entity那里加一个“院系”。然后回到utterance，把计算机系这几个字框住，然后标注为院系，save。就形成了一句标注的语句。</p>
<p>previous entity中有些时间年龄之类的內建。通过这种方式不停的去加训练数据。</p>
<p>再来看list feature，提供列表。给一个值之后有更多类似值推荐。</p>
<p><img src="http://i4.buimg.com/588926/fe0142a23cf05882.png" alt=""></p>
<p>点train application就开始训练。然后就可以测试了。</p>
<p>下一步就是发布，endpoint key选luistest，然后点publish，拿到一个url。通过get拿到结果</p>
<p>add flag勾上，timezone可以解决相对时间passing的问题，在postman中测试</p>
<p><img src="http://i4.buimg.com/588926/e935e29c11db9342.png" alt=""></p>
<p>再看看一个正常的bot（可以直接import dataset）</p>
<p><img src="http://i1.piimg.com/588926/e79a6d26aea6e5d9.png" alt=""></p>
<p><img src="http://i1.piimg.com/588926/404fea0903dde5e8.png" alt=""></p>
<p><img src="http://i2.muimg.com/588926/6ab68d4dee46a393.png" alt=""></p>
<p><img src="http://i2.muimg.com/588926/b1474cfb1fe31105.png" alt=""></p>
<p><img src="http://i2.muimg.com/588926/976048dd0747eb16.png" alt=""></p>
<p>batch testing里面增加数据集</p>
<p>dashbroad里面的suggested utterance：<br>通过发布的链接进来的所有的句子都会通过一个模块，推荐到这。选择一个模型，如capacity，然后相对应的句子加入到utterance单元中去<br><img src="http://i2.muimg.com/588926/ecca43ca6d4b210b.png" alt=""><br>通常这样做会得到一个更好的模型</p>
<h2 id="经验总结"><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h2><p>1、兵无常势<br>针对具体的任务选择规则还是数据<br>或者是两者的结合</p>
<p><img src="http://i2.muimg.com/588926/2f57cce1b7f491b5.png" alt=""></p>
<p>2、循序渐进</p>
<p><img src="http://i4.buimg.com/588926/445339e1fce78f50.png" alt=""></p>
<p>3、三思而行<br><img src="http://i1.piimg.com/588926/a71f92b2afa11423.png" alt=""></p>
<p>框架中具体的细节决定成败：模型方面、数据方面、如何交互、如何提示，简单易用和足够聪明</p>
<p><img src="http://i4.buimg.com/588926/005c6cdbcb2672d7.png" alt=""></p>
<p>1.介绍微软Bot Framework 的配置以及如何用Bot Framework SDK开发对话聊天机器人。2.介绍如何使用Bot Framework中的QnA Maker开发问答聊天机器人。3.介绍如何使用Bot Framework讲自己开发的聊天机器人发布到多个聊天工具中。4.用实际案例帮助大家熟悉Bot Framework的使用以及在开发过程中需要注意的问题。</p>
<p>Bot Framework开发框架，帮助开发者快速有效开发<br><img src="http://i1.piimg.com/588926/970e6c99fa4d0ff5.png" alt=""></p>
<h2 id="三大重要部分"><a href="#三大重要部分" class="headerlink" title="三大重要部分"></a>三大重要部分</h2><p><img src="http://i2.muimg.com/588926/4a6590d34c81c00d.png" alt=""></p>
<h3 id="一、bot-connector"><a href="#一、bot-connector" class="headerlink" title="一、bot connector"></a>一、bot connector</h3><p>帮助开发者将聊天机器人发布到交流平台上，所以开发者只需要开发一个后端服务，节省通讯端的开发成本</p>
<h3 id="二、bot-builder-sdks"><a href="#二、bot-builder-sdks" class="headerlink" title="二、bot builder sdks"></a>二、bot builder sdks</h3><p>开源sdk，快速生成开发模板，提供开发工具。这次参赛选手主要是和bot builder打交道</p>
<h3 id="三、bot-dicrectory"><a href="#三、bot-dicrectory" class="headerlink" title="三、bot dicrectory"></a>三、bot dicrectory</h3><p>像一个bot的商店，可以看到并用其他人开发的bot</p>
<p>今天主要是以实际操作为主<br>开发环境贮备和基本步骤<br>实际操作来快速上手</p>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>今天用C#。其他语言可以看官方文档<br>升级到最新版本</p>
<p><img src="http://i2.muimg.com/588926/91844ea7ffa02e17.png" alt=""></p>
<p>下载bot application template模板，然后拷到对应目录</p>
<p>引入bot bulider的sdk<br>直接从github上下载bot builder源码<br><img src="http://i2.muimg.com/588926/57dda6bb4a885e79.png" alt=""></p>
<p>最后，需要安装bot的模拟器<br><img src="http://i1.piimg.com/588926/8181680c86aef7d2.png" alt=""></p>
<h2 id="实际操作例子"><a href="#实际操作例子" class="headerlink" title="实际操作例子"></a>实际操作例子</h2><p>官网<br><img src="http://i2.muimg.com/588926/a252247342003321.png" alt=""><br>注意看文档（包括如何连接人工智能的工具louis、关于图像和语音的api）</p>
<p>下载<br><img src="http://i4.buimg.com/588926/a554c284cda1ec2c.png" alt="">，解压之后放到vs的temple文件夹里面</p>
<p>新建一个工程<br><img src="http://i4.buimg.com/588926/3d61a1329b6cd8ca.png" alt=""></p>
<p>new bop 包的使用<br><img src="http://i4.buimg.com/588926/ae6c811a7f3774f4.png" alt=""><br>然后在browse搜寻bot builder，然后installupdate，</p>
<p>messagecontroller是我们主要要面对的，用于收发用户的消息<br><img src="http://i1.piimg.com/588926/24d215693d910900.png" alt=""></p>
<p>dialogs就是对话的主要组成，今天主要来看在收发消息的时候怎么和用户进行交流，进入rootdialog<br><img src="http://i1.piimg.com/588926/b7f29b53a4aac9c4.png" alt=""></p>
<p>有个函数交messagerecieveasunc，收到消息返回的方法，<br><img src="http://i1.piimg.com/588926/ae13cf2e025d743a.png" alt=""></p>
<p>得到是result转化成activity，是一个类，回复是文字</p>
<p>看一下demo，问题和答案<br><img src="http://i4.buimg.com/588926/520991b8a678e063.png" alt=""></p>
<p>用模拟器来调试<br><img src="http://i1.piimg.com/588926/142254231808f366.png" alt=""><br><img src="http://i1.piimg.com/588926/fbaaedfece8021f6.png" alt=""></p>
<p>编译运行<br>![](<a href="http://i4.buimg.com/588926/f4cfe0c8c5ed57c9.png" target="_blank" rel="external">http://i4.buimg.com/588926/f4cfe0c8c5ed57c9.png</a><br>会发布一个http本地服务，在模拟器中后缀<a href="http://localhost:3979/api/messages" target="_blank" rel="external">http://localhost:3979/api/messages</a></p>
<p>另外一个多轮对话的demo</p>
<h2 id="对于Louis"><a href="#对于Louis" class="headerlink" title="对于Louis"></a>对于Louis</h2><p>新建一个app，新建两个entity，一个是教学楼一个是系别<br><img src="http://i4.buimg.com/588926/416c43b92f1d066e.png" alt=""><br><img src="http://i4.buimg.com/588926/7866fe54dcebebea.png" alt=""><br><img src="http://i4.buimg.com/588926/b4a695c004cfbb95.png" alt=""><br><img src="http://i4.buimg.com/588926/5e8a6b7c26eaa3c9.png" alt=""><br><img src="http://i4.buimg.com/588926/1e5a250bb82448c5.png" alt=""><br><img src="http://i4.buimg.com/588926/4182bef4b6be7768.png" alt=""><br><img src="http://i4.buimg.com/588926/a524474baa6cd4c4.png" alt=""><br>需要丰富<br><img src="http://i4.buimg.com/588926/0addf7f56b7c4c31.png" alt=""><br>train之后publish</p>
<p><img src="http://i4.buimg.com/588926/0addf7f56b7c4c31.png" alt=""><br>返回json的结果，识别问句的意图，得到关键属性，然后bot框架 则帮我们包装，让我们更快的使用louis的结果<br><img src="http://i4.buimg.com/588926/ed50fa1d45204952.png" alt=""></p>
<p><img src="http://i4.buimg.com/588926/54d93f646e2f3a99.png" alt=""></p>
<p>在luismodel中填入luis的id和key，节省开发时间，要定义两个常量即是entity里面的系别和教学楼<br><img src="http://i1.piimg.com/588926/c55c075d0189cacd.png
可以写一些处理的方法，luisintnet写在方法的最前面，luisintnet中是某个值的话，就调用这个方法，方法中还可以进一步写逻辑
![](http://i1.piimg.com/588926/5ac49d4025a3ea8b.png" alt=""><br>具体看查询位置的方法，试图得到building的值，看json结构中有没有entity，然后回复位置在哪<br><img src="http://i1.piimg.com/588926/85cc82644e424616.png" alt=""><br><img src="http://i1.piimg.com/588926/85cc82644e424616.png" alt=""></p>
<p><img src="http://i1.piimg.com/588926/92f446f4e585a783.png" alt=""></p>
<p>前面这个例子讲解了bot框架怎么来和luis链接，来让luis处理nlp中的意图识别和实体抽取的问题，然后用bot框架来执行相应的逻辑，并和用户进行交流，最后再看个更加复杂的例子:表单。对于填表，提供了一套框架</p>
<p>先定义一个枚举类型：男还是女<br><img src="http://i4.buimg.com/588926/2a0b14dc4a156547.png" alt=""><br>还有一些模板的定义，定义了四个关键的属性<br><img src="http://i1.piimg.com/588926/6faa3a8e34a6a8ce.png" alt=""><br><img src="http://i1.piimg.com/588926/33d7b026ab1fadd7.png" alt=""><br>numeric对用户输入进行校验<br><img src="http://i1.piimg.com/588926/5ce240ac964d0b7e.png" alt=""><br>pattern快速写一个正则表达式<br><img src="http://i1.piimg.com/588926/86ed0a70c5e6fa88.png" alt=""></p>
<p>回调函数，然后看看formbuilder</p>
<p>有些关键词<br>message、field、confirm、oncompletion、build</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/16/计算机专业导论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/16/计算机专业导论/" itemprop="url">
                  计算机专业导论
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-16T23:47:59+08:00">
                2017-05-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>针对计算机课程自学话题，画出一张计算机专业流程图，并结合几个最重要的课程，具体讲学习方法<br><img src="https://pic1.zhimg.com/v2-c03d3e08d3d59f3ad4188ad90a273bf8_b.jpg" alt=""></p>
<p><img src="https://pic2.zhimg.com/v2-4981e4469fe1d246d8b1925b0c107b35_b.jpg" alt=""></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/16/计算机专业导论/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/16/query入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/16/query入门/" itemprop="url">
                  query入门
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-16T11:00:05+08:00">
                2017-05-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="主要内容：对通用搜索引擎的查询推荐技术的方法、评价进行了总结"><a href="#主要内容：对通用搜索引擎的查询推荐技术的方法、评价进行了总结" class="headerlink" title="主要内容：对通用搜索引擎的查询推荐技术的方法、评价进行了总结"></a>主要内容：对通用搜索引擎的查询推荐技术的方法、评价进行了总结</h1><h1 id="具体内容："><a href="#具体内容：" class="headerlink" title="具体内容："></a>具体内容：</h1><p>“查询推荐”的不同英文叫法：Query Suggestion、Term Suggestion、Query Recommendation、Query Substitution、Query Rewriting</p>
<p>查询推荐的任务：找出和用户查询相似的query，以便更好地表达用户查询意图，供用户便捷输入</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/16/query入门/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/15/吴岸成《NN-and-DL》/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/15/吴岸成《NN-and-DL》/" itemprop="url">
                  吴岸成《NN and DL》
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-15T23:32:11+08:00">
                2017-05-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>机器学习和神经网络入门</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/15/吴岸成《NN-and-DL》/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/14/课堂精灵/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/14/课堂精灵/" itemprop="url">
                  课堂精灵
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-14T17:09:13+08:00">
                2017-05-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>服务器地址mana-cyan.cn，账号op，项目位置/project/CourseSpirit</p>
<p>ssh op@mana-cyan.cn</p>
<p>密码</p>
<p>cd /project/CourseSpirit</p>
<p>cd apis</p>
<p>exit</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/14/nlp入门笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/14/nlp入门笔记/" itemprop="url">
                  nlp入门笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-14T03:01:53+08:00">
                2017-05-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>nlp入门学习</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/14/nlp入门笔记/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/13/Distant-supervision/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒TANG的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/13/Distant-supervision/" itemprop="url">
                  Distant supervision
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-13T11:06:49+08:00">
                2017-05-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>远程监督：使用未标注语料做关系抽取</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2017/05/13/Distant-supervision/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="唐相儒" />
          <p class="site-author-name" itemprop="name">唐相儒</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/目录">
                <span class="site-state-item-count">18</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">唐相儒</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  


  

</body>
</html>
